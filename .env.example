# ============================================================================
# MCP Local Knowledge - Environment Variables
# ============================================================================
# Copy this file to .env in your project root or set these variables in your
# shell environment. Environment variables take precedence over config.json.
# All settings are optional - the system will use defaults if not specified.
#
# IMPORTANT: Python Docling Required
# -----------------------------------
# This package requires Python Docling for document conversion.
# Install it once before first use:
#   pip install docling
#
# Requirements:
#   - Python 3.10 or higher
#   - Docling package (pip install docling)
#
# The postinstall script will check for Docling and display installation
# instructions if it's not found.
# ============================================================================

# LanceDB Configuration
# ----------------------
# Directory where LanceDB persists vector data
# Default: ~/.knowledge-base/lancedb
LANCEDB_PERSIST_PATH=~/.knowledge-base/lancedb

# Embedding Model Configuration
# ------------------------------
# Hugging Face model name for generating embeddings
# Default: Xenova/all-MiniLM-L6-v2
# Alternative models:
#   - Xenova/all-MiniLM-L12-v2 (larger, more accurate, slower)
#   - Xenova/paraphrase-MiniLM-L6-v2 (optimized for paraphrasing)
# Note: Changing models requires re-ingesting all knowledge bases
EMBEDDING_MODEL_NAME=Xenova/all-MiniLM-L6-v2

# Directory where embedding models are cached after download
# Default: ~/.knowledge-base/models
# Models are ~100MB and downloaded once on first use
EMBEDDING_CACHE_PATH=~/.knowledge-base/models

# Fastify Server Configuration
# -----------------------------
# Port number for the Manager UI HTTP server
# Default: 8009
# Change this if port 8009 is already in use
SERVER_PORT=8009

# Host address to bind the server to
# Default: localhost
# WARNING: Do not change to 0.0.0.0 unless you understand the security implications
SERVER_HOST=localhost

# Ingestion Configuration
# -----------------------
# Number of chunks to process in each batch during ingestion
# Default: 100
# Higher values = faster ingestion but more memory usage
# Recommended range: 50-200
INGESTION_BATCH_SIZE=100

# Maximum file size in bytes to process
# Default: 52428800 (50MB)
# Files larger than this are skipped with a warning
# Example values: 10485760 (10MB), 52428800 (50MB), 104857600 (100MB)
INGESTION_MAX_FILE_SIZE=52428800

# Search Configuration
# --------------------
# Default maximum number of results to return per search
# Default: 50
# Can be overridden per-query via the maxResults parameter
# Maximum allowed: 200 (enforced by the system)
SEARCH_DEFAULT_MAX_RESULTS=50

# Cache timeout in seconds for search results
# Default: 60
# Identical queries within this timeframe return cached results
# Set to 0 to disable caching (not recommended)
SEARCH_CACHE_TIMEOUT_SECONDS=60

# Document Processing Configuration (Docling Integration)
# --------------------------------------------------------
# These settings control how documents are converted and chunked using Docling.
# Docling is a Python library that converts various document formats (PDF, DOCX,
# PPTX, XLSX, HTML, audio) to markdown with structure preservation.
#
# Prerequisites:
#   - Python 3.10 or higher
#   - Docling installed: pip install docling
#   - docling-sdk npm package (installed automatically)
#
# The system uses docling-sdk (TypeScript wrapper) which communicates with
# Python Docling via CLI mode for document conversion and chunking.

# Timeout in milliseconds for document conversion operations
# Default: 30000 (30 seconds)
# Increase this for large or complex documents:
#   - PDFs with many pages or high-resolution images
#   - Large DOCX files with embedded media
#   - Audio files requiring transcription (MP3, WAV, M4A, FLAC)
# Recommended range: 10000-60000
# Note: Conversion that exceeds this timeout will attempt fallback text extraction
DOCUMENT_CONVERSION_TIMEOUT=30000

# Maximum tokens per chunk when using Docling's HybridChunker
# Default: 512
# HybridChunker is Docling's structure-aware, token-aware chunking algorithm that:
#   - Preserves document structure (headings, sections, tables)
#   - Respects token boundaries for optimal embedding generation
#   - Includes heading hierarchy as context
# Larger values = fewer chunks but less granular search results
# Smaller values = more chunks with more precise search targeting
# Recommended range: 256-1024
# Adjust based on your use case:
#   - 256: Fine-grained search, more chunks, slower ingestion
#   - 512: Balanced (recommended for most use cases)
#   - 1024: Coarse-grained search, fewer chunks, faster ingestion
DOCUMENT_MAX_TOKENS=512

# Chunk size in characters for fallback text chunking
# Default: 1000
# Used when Docling's HybridChunker is not available or fails
# This is a simple character-based chunking strategy without structure awareness
# Recommended range: 500-2000
# Note: HybridChunker is preferred; this is only a fallback mechanism
DOCUMENT_CHUNK_SIZE=1000

# Overlap in characters between consecutive chunks for fallback chunking
# Default: 200
# Helps maintain context across chunk boundaries when using fallback chunking
# Higher overlap = better context preservation but more redundancy
# Recommended range: 100-400 (typically 10-20% of DOCUMENT_CHUNK_SIZE)
# Note: Only applies to fallback chunking; HybridChunker manages overlap automatically
DOCUMENT_CHUNK_OVERLAP=200

# Docling Output Directory (optional)
# Default: System temp directory
# Directory where Docling stores temporary conversion files (markdown, JSON)
# These files are automatically cleaned up after processing
# Uncomment to specify a custom location:
# DOCLING_OUTPUT_DIR=~/.knowledge-base/temp

# Docling Chunker Type (optional)
# Default: hybrid
# Options: hybrid, hierarchical
#   - hybrid: Token-aware chunking with structure preservation (recommended)
#   - hierarchical: Pure structure-based chunking
# Note: Most users should use the default (hybrid)
# DOCLING_CHUNKER_TYPE=hybrid

# Docling Merge Peers (optional)
# Default: true
# When true, HybridChunker merges adjacent chunks of the same type
# This reduces chunk count and improves coherence
# Set to false for maximum granularity
# DOCLING_MERGE_PEERS=true

# Logging Configuration
# ---------------------
# Log level for all components
# Default: info
# Options: debug, info, warn, error
# Use "debug" for troubleshooting, "info" for normal operation
LOG_LEVEL=info

# Configuration File Path (optional)
# -----------------------------------
# Path to JSON configuration file
# If specified, settings from the file will be merged with environment variables
# Environment variables take precedence over config file settings
# CONFIG_PATH=~/.knowledge-base/config.json
